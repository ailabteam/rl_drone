# scripts/evaluate.py

import time
import argparse
import os

import gymnasium as gym
import torch
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize

# Import môi trường và hàm sync
import gym_pybullet_drones
from gym_pybullet_drones.utils.utils import sync

def evaluate(model_path: str, vec_normalize_path: str, env_id: str, n_episodes: int):
    """
    Đánh giá và trực quan hóa một agent đã huấn luyện.
    """
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model file not found at: {model_path}")
    if not os.path.exists(vec_normalize_path):
        raise FileNotFoundError(f"VecNormalize stats file not found at: {vec_normalize_path}")

    model = PPO.load(model_path)
    print(f"Model loaded from {model_path}")

    # Tạo môi trường DummyVecEnv (chỉ 1 env) có bật GUI
    eval_env_creator = lambda: gym.make(env_id, gui=True)
    eval_env = DummyVecEnv([eval_env_creator])
    
    # Lấy timestep của môi trường để dùng cho hàm sync
    # Chúng ta cần truy cập vào môi trường gốc bên trong DummyVecEnv
    TIMESTEP = eval_env.get_attr("TIMESTEP")[0]

    eval_env = VecNormalize.load(vec_normalize_path, eval_env)
    eval_env.training = False
    eval_env.norm_reward = False

    print("Evaluation environment created.")

    obs = eval_env.reset()
    for episode in range(n_episodes):
        # Khởi tạo lại thời gian bắt đầu và biến đếm cho mỗi episode
        start_time = time.time()
        step_counter = 0
        terminated = False
        truncated = False
        total_reward = 0
        print(f"\n--- Starting Episode {episode + 1}/{n_episodes} ---")
        
        while not terminated and not truncated:
            action, _states = model.predict(obs, deterministic=True)
            obs, reward, terminated, info = eval_env.step(action)
            total_reward += reward[0]

            # Gọi hàm sync với đúng tham số: (iteration, start_time, timestep)
            sync(step_counter, start_time, TIMESTEP)
            
            # Tăng biến đếm
            step_counter += 1

            if terminated or truncated:
                print(f"Episode finished. Total Reward: {total_reward:.2f}")
                obs = eval_env.reset()

    eval_env.close()
    print("\n--- Evaluation finished ---")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Evaluate a trained RL agent for drones.")
    
    parser.add_argument(
        "--exp-dir", type=str, required=True,
        help="Path to the experiment directory."
    )
    parser.add_argument(
        "--episodes", type=int, default=5,
        help="Number of episodes to run for evaluation."
    )
    
    args = parser.parse_args()

    model_file = os.path.join(args.exp_dir, "models/best_model.zip")
    vec_normalize_file = os.path.join(args.exp_dir, "models/vec_normalize.pkl")
    
    ENV_ID = "hover-aviary-v0"

    evaluate(
        model_path=model_file,
        vec_normalize_path=vec_normalize_file,
        env_id=ENV_ID,
        n_episodes=args.episodes
    )
